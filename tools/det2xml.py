#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time : 18-11-27 下午7:40
# @Author : Moyan
# @Software: PyCharm

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import detectron.datasets.dummy_datasets as dummy_datasets
from lxml.etree import Element, SubElement, tostring
from xml.dom.minidom import parseString
import argparse
import detectron.utils.c2 as c2_utils
import detectron.core.test_engine as infer_engine
from detectron.core.config import merge_cfg_from_file
from detectron.core.config import cfg
from detectron.core.config import assert_and_infer_cfg
from caffe2.python import workspace
import numpy as np
import cv2  # NOQA (Must import before importing caffe2 due to bug in cv2)
import os
import sys

os.environ['CUDA_VISIBLE_DEVICES'] = '1'

reload(sys)
sys.setdefaultencoding('utf-8')

c2_utils.import_detectron_ops()
cv2.ocl.setUseOpenCL(False)


def parse_args():
    parser = argparse.ArgumentParser(
        description='Detectron api, Input test_imgs Dir, Output xml')
    parser.add_argument(
        '--m',
        dest='model',
        help='detect model.pkl',
        default='model.pkl',
        type=str
    )
    parser.add_argument(
        '--c',
        dest='cfg_file',
        help='test config.yaml',
        default='config.yaml',
        type=str
    )
    parser.add_argument(
        '--t',
        dest='test_dir',
        help='test img root',
        default='demo',
        type=str
    )
    parser.add_argument(
        '--thresh',
        dest='thresh',
        help='bbox thresh',
        default=0.5,
        type=float
    )
    return parser.parse_args()


def get_class_string(class_index, dataset):
    class_text = dataset.classes[class_index] if dataset is not None else \
        'id{:d}'.format(class_index)
    return class_text


def rewrite_xml_clean(bbox, img_name, xml_path):
    # [ { 'width': xx ; 'depth' : xx ; 'height': xx} ; {'name' : 'class_name' ; 'bbox' : [xmin ymin xmax ymax] }  ]
    node_root = Element('annotation')
    ####
    node_filename = SubElement(node_root, 'filename')
    node_filename.text = img_name.decode('utf-8')
    node_size = SubElement(node_root, 'size')
    node_width = SubElement(node_size, 'width')
    node_width.text = bbox[0]['width']
    node_height = SubElement(node_size, 'height')
    node_height.text = bbox[0]['height']
    node_depth = SubElement(node_size, 'depth')
    node_depth.text = '3'
    for i in range(1, len(bbox)):
        node_object = SubElement(node_root, 'object')
        node_name = SubElement(node_object, 'name')
        node_name.text = str(bbox[i]['name'])
        node_difficult = SubElement(node_object, 'difficult')
        node_difficult.text = '0'
        node_score = SubElement(node_object, 'score')
        node_score.text = str(float(bbox[i]['score']))
        node_bndbox = SubElement(node_object, 'bndbox')
        node_xmin = SubElement(node_bndbox, 'xmin')
        node_xmin.text = str(float(bbox[i]['bbox'][0]))
        node_ymin = SubElement(node_bndbox, 'ymin')
        node_ymin.text = str(float(bbox[i]['bbox'][1]))
        node_xmax = SubElement(node_bndbox, 'xmax')
        node_xmax.text = str(float(bbox[i]['bbox'][2]))
        node_ymax = SubElement(node_bndbox, 'ymax')
        node_ymax.text = str(float(bbox[i]['bbox'][3]))

    xml = tostring(node_root, pretty_print=False)  # 格式化显示，该换行的换行
    dom = parseString(xml)
    # print xml
    f = open(xml_path, 'w')
    dom.writexml(f, addindent='  ', newl='\n', encoding='utf-8')
    f.close()


def convert_from_cls_format(cls_boxes, cls_segms, cls_keyps):
    """Convert from the class boxes/segms/keyps format generated by the testing
    code.
    """
    box_list = [b for b in cls_boxes if len(b) > 0]
    if len(box_list) > 0:
        boxes = np.concatenate(box_list)
    else:
        boxes = None
    if cls_segms is not None:
        segms = [s for slist in cls_segms for s in slist]
    else:
        segms = None
    if cls_keyps is not None:
        keyps = [k for klist in cls_keyps for k in klist]
    else:
        keyps = None
    classes = []
    for j in range(len(cls_boxes)):
        classes += [j] * len(cls_boxes[j])
    return boxes, segms, keyps, classes


class mycaffe2(object):
    def __init__(self, cfg_file, weights, gpu_id=0, thresh_=0.5):
        self.gpu_id = gpu_id
        self.thresh = thresh_
        self.classs = dummy_datasets.get_libyposm191024_dataset()  # get_surveyPOSM_dataset get_idtSKU_dataset get_ulposm_dataset
        workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])
        merge_cfg_from_file(cfg_file)
        cfg.NUM_GPUS = 1
        assert_and_infer_cfg(cache_urls=False)
        self.model = infer_engine.initialize_model_from_cfg(weights, gpu_id)

    def detect(self, img):
        
        im = cv2.imread(img)

        # filter img is 0kb
        if im is None:
            return None

        with c2_utils.NamedCudaScope(self.gpu_id):
            cls_boxes, cls_segms, cls_keyps = infer_engine.im_detect_all(
                self.model, im, None)

        if isinstance(cls_boxes, list):
            boxes, segms, keypoints, classes = convert_from_cls_format(
                cls_boxes, cls_segms, cls_keyps)
        if (boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < self.thresh) and not False:
            return

        if boxes is None:
            sorted_inds = []  # avoid crash when 'boxes' is None
        else:
            # Display in largest to smallest order to reduce occlusion
            areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
            sorted_inds = np.argsort(-areas)
        box_dict = []
        pic_struct = {}
        pic_struct['width'] = str(im.shape[1])
        pic_struct['height'] = str(im.shape[0])
        pic_struct['depth'] = str(im.shape[2])
        box_dict.append(pic_struct)
        for i in sorted_inds:
            obj_struct = {}
            obj_struct['bbox'] = boxes[i, :4]
            score = boxes[i, -1]
            if score < self.thresh:
                continue
            obj_struct['name'] = get_class_string(classes[i], self.classs)
            obj_struct['score'] = score
            box_dict.append(obj_struct)

        return box_dict


if __name__ == '__main__':

    cwd = os.getcwd()
    args = parse_args()
    
    cfg_file = args.cfg_file
    weights = args.model
    assert os.path.exists(cfg_file)
    assert os.path.exists(weights)

    det_API = mycaffe2(cfg_file, weights, thresh_=args.thresh)
    detDir = args.test_dir
    assert os.path.exists(detDir)
    detList = os.listdir(detDir)

    # output_dir = os.path.join(cwd, 'Annotations')
    output_dir = os.path.join(os.path.dirname(detDir), 'Annotations')
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    for idx, nname in enumerate(detList):
        print('loading {}, name: {}'.format(idx, nname))
        imgPath = os.path.join(detDir, nname)
        predict_dict = det_API.detect(imgPath)

        # '''按类别过滤，选取需要的类别'''
        # if predict_dict:
        #     class_all = [predict_dict[idx]['name'] for idx in range(1, len(predict_dict))]
        #     if '17779' not in class_all:
        #         continue
        # else:
        #     continue

        if predict_dict:
            outxml_path = os.path.join(output_dir, nname.strip().replace(
                '.jpg', '.xml').replace('.JPG', '.xml'))
            try:
                rewrite_xml_clean(predict_dict, nname, outxml_path)
            except:
                pass


'''
export PYTHONIOENCODING=utf-8
'''
